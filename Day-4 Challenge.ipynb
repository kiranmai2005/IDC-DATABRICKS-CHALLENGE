{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d8c2acc3-1126-4e0d-850e-a6b3a0cd83c4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr></tr></thead><tbody></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [],
       "datasetInfos": [
        {
         "name": "_sqldf",
         "schema": {
          "fields": [],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.connect.dataframe.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 2
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "CREATE SCHEMA IF NOT EXISTS workspace.ecommerce;\n",
    "USE CATALOG workspace;\n",
    "USE SCHEMA ecommerce;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7e4192ad-cb3d-4128-a01f-4c44650a41c2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- event_time: timestamp (nullable = true)\n |-- event_type: string (nullable = true)\n |-- product_id: integer (nullable = true)\n |-- category_id: long (nullable = true)\n |-- category_code: string (nullable = true)\n |-- brand: string (nullable = true)\n |-- price: double (nullable = true)\n |-- user_id: integer (nullable = true)\n |-- user_session: string (nullable = true)\n\n+-------------------+----------+----------+-------------------+--------------------+------+------+---------+--------------------+\n|         event_time|event_type|product_id|        category_id|       category_code| brand| price|  user_id|        user_session|\n+-------------------+----------+----------+-------------------+--------------------+------+------+---------+--------------------+\n|2019-11-01 00:00:00|      view|   1003461|2053013555631882655|electronics.smart...|xiaomi|489.07|520088904|4d3b30da-a5e4-49d...|\n|2019-11-01 00:00:00|      view|   5000088|2053013566100866035|appliances.sewing...|janome|293.65|530496790|8e5f4f83-366c-4f7...|\n|2019-11-01 00:00:01|      view|  17302664|2053013553853497655|                NULL| creed| 28.31|561587266|755422e7-9040-477...|\n|2019-11-01 00:00:01|      view|   3601530|2053013563810775923|appliances.kitche...|    lg|712.87|518085591|3bfb58cd-7892-48c...|\n|2019-11-01 00:00:01|      view|   1004775|2053013555631882655|electronics.smart...|xiaomi|183.27|558856683|313628f1-68b8-460...|\n+-------------------+----------+----------+-------------------+--------------------+------+------+---------+--------------------+\nonly showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(\n",
    "    \"/Volumes/workspace/ecommerce/ecommerce_data\",\n",
    "    header=True,\n",
    "    inferSchema=True\n",
    ")\n",
    "\n",
    "df.printSchema()\n",
    "df.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c0aa2a38-070e-4494-a35e-fdf968c36e4f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+--------------------+\n|product_id|  brand|       total_revenue|\n+----------+-------+--------------------+\n|   1005115|  apple|3.3032381669999924E7|\n|   1005105|  apple| 2.168460337000001E7|\n|   1004249|  apple|1.3545407540000014E7|\n|   1005135|  apple|1.2654328769999998E7|\n|   1004767|samsung|1.1004748489999998E7|\n+----------+-------+--------------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "top_revenue_products = (\n",
    "    df.filter(F.col(\"event_type\") == \"purchase\")\n",
    "      .groupBy(\"product_id\", \"brand\")\n",
    "      .agg(F.sum(\"price\").alias(\"total_revenue\"))\n",
    "      .orderBy(F.desc(\"total_revenue\"))\n",
    "      .limit(5)\n",
    ")\n",
    "\n",
    "top_revenue_products.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f81c19d4-5f5a-44ae-90d2-13cdc492879a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-----------------+\n| user_id|         event_time|cumulative_events|\n+--------+-------------------+-----------------+\n|65800726|2019-11-27 04:33:16|                1|\n|65800726|2019-11-27 04:35:24|                2|\n|81255481|2019-11-08 07:44:45|                1|\n|81255481|2019-11-21 14:11:26|                2|\n|82079354|2019-11-28 04:58:01|                1|\n+--------+-------------------+-----------------+\nonly showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.window import Window\n",
    "\n",
    "window_spec = Window.partitionBy(\"user_id\").orderBy(\"event_time\")\n",
    "\n",
    "df_with_running_total = df.withColumn(\n",
    "    \"cumulative_events\",\n",
    "    F.count(\"*\").over(window_spec)\n",
    ")\n",
    "\n",
    "df_with_running_total.select(\n",
    "    \"user_id\", \"event_time\", \"cumulative_events\"\n",
    ").show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "08a8af6c-8373-458a-9f21-babf36c93fb8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+---------+-------------------+\n|       category_code|   views|purchases|    conversion_rate|\n+--------------------+--------+---------+-------------------+\n| stationery.cartrige|   19323|      325| 1.6819334471872898|\n|electronics.video.tv| 3127266|    51839| 1.6576460077268773|\n|  accessories.wallet|  112191|      676| 0.6025438760684904|\n|appliances.kitche...|  118134|     1287| 1.0894408045101325|\n|                NULL|34073918|   407643| 1.1963490667553993|\n|construction.tool...|  233215|     2200| 0.9433355487425765|\n|appliances.enviro...|  422673|     6066| 1.4351519969337998|\n|country_yard.furn...|    2785|        4| 0.1436265709156194|\n|       apparel.shoes| 2596322|    14395|  0.554438162908915|\n|electronics.audio...|   73039|      919| 1.2582319035036076|\n|appliances.kitche...|  238132|     1659| 0.6966724337762249|\n|electronics.audio...|  615955|     6478| 1.0517002053721458|\n|country_yard.lawn...|   11580|       82| 0.7081174438687392|\n|furniture.kitchen...|  297643|     2026|  0.680681218775513|\n|electronics.audio...|  231337|     2041| 0.8822626730700233|\n|apparel.shoes.bal...|    7234|       33|0.45617915399502346|\n|auto.accessories....|  144528|     1291| 0.8932525185431197|\n|appliances.enviro...|  332859|     6156| 1.8494317413679666|\n|   computers.desktop| 1091654|     7013|  0.642419667770191|\n|   apparel.underwear|   91519|      181| 0.1977731400037151|\n+--------------------+--------+---------+-------------------+\nonly showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "conversion = (\n",
    "    df.groupBy(\"category_code\")\n",
    "      .agg(\n",
    "          F.sum(F.when(F.col(\"event_type\") == \"view\", 1).otherwise(0)).alias(\"views\"),\n",
    "          F.sum(F.when(F.col(\"event_type\") == \"purchase\", 1).otherwise(0)).alias(\"purchases\")\n",
    "      )\n",
    "      .withColumn(\n",
    "          \"conversion_rate\",\n",
    "          (F.col(\"purchases\") / F.col(\"views\")) * 100\n",
    "      )\n",
    ")\n",
    "\n",
    "conversion.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b66830c4-34d1-4cbd-ba2d-9c33bfe7b9bc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .saveAsTable(\"workspace.ecommerce.events_delta\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a9b4282e-4ee8-4a8a-af63-3b9fe7a250aa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>format</th><th>id</th><th>name</th><th>description</th><th>location</th><th>createdAt</th><th>lastModified</th><th>partitionColumns</th><th>clusteringColumns</th><th>numFiles</th><th>sizeInBytes</th><th>properties</th><th>minReaderVersion</th><th>minWriterVersion</th><th>tableFeatures</th><th>statistics</th><th>clusterByAuto</th></tr></thead><tbody><tr><td>delta</td><td>e25176cf-ea06-4746-b507-c4b1078a8d04</td><td>workspace.ecommerce.events_delta</td><td>null</td><td></td><td>2026-01-12T16:40:34.072Z</td><td>2026-01-12T16:41:39.000Z</td><td>List()</td><td>List()</td><td>111</td><td>1916063378</td><td>Map(delta.parquet.compression.codec -> zstd, delta.enableDeletionVectors -> true)</td><td>3</td><td>7</td><td>List(appendOnly, deletionVectors, invariants)</td><td>Map(numRowsDeletedByDeletionVectors -> 0, numDeletionVectors -> 0)</td><td>false</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "delta",
         "e25176cf-ea06-4746-b507-c4b1078a8d04",
         "workspace.ecommerce.events_delta",
         null,
         "",
         "2026-01-12T16:40:34.072Z",
         "2026-01-12T16:41:39.000Z",
         [],
         [],
         111,
         1916063378,
         {
          "delta.enableDeletionVectors": "true",
          "delta.parquet.compression.codec": "zstd"
         },
         3,
         7,
         [
          "appendOnly",
          "deletionVectors",
          "invariants"
         ],
         {
          "numDeletionVectors": 0,
          "numRowsDeletedByDeletionVectors": 0
         },
         false
        ]
       ],
       "datasetInfos": [
        {
         "name": "_sqldf",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "format",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "id",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "name",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "description",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "location",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "createdAt",
            "nullable": true,
            "type": "timestamp"
           },
           {
            "metadata": {},
            "name": "lastModified",
            "nullable": true,
            "type": "timestamp"
           },
           {
            "metadata": {},
            "name": "partitionColumns",
            "nullable": true,
            "type": {
             "containsNull": true,
             "elementType": "string",
             "type": "array"
            }
           },
           {
            "metadata": {},
            "name": "clusteringColumns",
            "nullable": true,
            "type": {
             "containsNull": true,
             "elementType": "string",
             "type": "array"
            }
           },
           {
            "metadata": {},
            "name": "numFiles",
            "nullable": true,
            "type": "long"
           },
           {
            "metadata": {},
            "name": "sizeInBytes",
            "nullable": true,
            "type": "long"
           },
           {
            "metadata": {},
            "name": "properties",
            "nullable": true,
            "type": {
             "keyType": "string",
             "type": "map",
             "valueContainsNull": true,
             "valueType": "string"
            }
           },
           {
            "metadata": {},
            "name": "minReaderVersion",
            "nullable": true,
            "type": "integer"
           },
           {
            "metadata": {},
            "name": "minWriterVersion",
            "nullable": true,
            "type": "integer"
           },
           {
            "metadata": {},
            "name": "tableFeatures",
            "nullable": true,
            "type": {
             "containsNull": true,
             "elementType": "string",
             "type": "array"
            }
           },
           {
            "metadata": {},
            "name": "statistics",
            "nullable": true,
            "type": {
             "keyType": "string",
             "type": "map",
             "valueContainsNull": true,
             "valueType": "long"
            }
           },
           {
            "metadata": {},
            "name": "clusterByAuto",
            "nullable": false,
            "type": "boolean"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.connect.dataframe.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 10
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "format",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "id",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "description",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "location",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "createdAt",
         "type": "\"timestamp\""
        },
        {
         "metadata": "{}",
         "name": "lastModified",
         "type": "\"timestamp\""
        },
        {
         "metadata": "{}",
         "name": "partitionColumns",
         "type": "{\"containsNull\":true,\"elementType\":\"string\",\"type\":\"array\"}"
        },
        {
         "metadata": "{}",
         "name": "clusteringColumns",
         "type": "{\"containsNull\":true,\"elementType\":\"string\",\"type\":\"array\"}"
        },
        {
         "metadata": "{}",
         "name": "numFiles",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "sizeInBytes",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "properties",
         "type": "{\"keyType\":\"string\",\"type\":\"map\",\"valueContainsNull\":true,\"valueType\":\"string\"}"
        },
        {
         "metadata": "{}",
         "name": "minReaderVersion",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "minWriterVersion",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "tableFeatures",
         "type": "{\"containsNull\":true,\"elementType\":\"string\",\"type\":\"array\"}"
        },
        {
         "metadata": "{}",
         "name": "statistics",
         "type": "{\"keyType\":\"string\",\"type\":\"map\",\"valueContainsNull\":true,\"valueType\":\"long\"}"
        },
        {
         "metadata": "{}",
         "name": "clusterByAuto",
         "type": "\"boolean\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "DESCRIBE DETAIL workspace.ecommerce.events_delta;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3ac9c006-63ae-4c5f-a52b-fda606a3ba94",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema enforcement works:\n[_LEGACY_ERROR_TEMP_DELTA_0007] A schema mismatch detected when writing to the Delta table (Table ID: e25176cf-ea06-4746-b507-c4b1078a8d04).\nTo enable schema migration using DataFrameWriter or DataStreamWriter, please set:\n'.option(\"mergeSchema\", \"true\")'.\nFor other operations, set the session configuration\nspark.databricks.delta.schema.autoMerge.enabled to \"true\". See the documentation\nspecific to the operation for details.\n\nTable schema:\nroot\n-- event_time: timestamp (nullable = true)\n-- event_type: string (nullable = true)\n-- product_id: integer (nullable = true)\n-- category_id: long (nullable = true)\n-- category_code: string (nullable = true)\n-- brand: string (nullable = true)\n-- price: double (nullable = true)\n-- user_id: integer (nullable = true)\n-- user_session: string (nullable = true)\n\n\nData schema:\nroot\n-- x: string (nullable = true)\n-- y: string (nullable = true)\n-- z: string (nullable = true)\n\n         \nTable ACLs are enabled in this cluster, so automatic schema migration is not allowed. Please use the ALTER TABLE command for changing the schema.         \n\nJVM stacktrace:\ncom.databricks.sql.transaction.tahoe.DeltaAnalysisException\n\tat com.databricks.sql.transaction.tahoe.MetadataMismatchErrorBuilder.finalizeAndThrow(DeltaErrors.scala:4310)\n\tat com.databricks.sql.transaction.tahoe.schema.ImplicitMetadataOperation.updateMetadata(ImplicitMetadataOperation.scala:231)\n\tat com.databricks.sql.transaction.tahoe.schema.ImplicitMetadataOperation.updateMetadata$(ImplicitMetadataOperation.scala:92)\n\tat com.databricks.sql.transaction.tahoe.commands.WriteIntoDeltaEdge.updateMetadata(WriteIntoDeltaEdge.scala:120)\n\tat com.databricks.sql.transaction.tahoe.commands.WriteIntoDeltaEdge.writeAndReturnCommitDataAndMaterializationPlans(WriteIntoDeltaEdge.scala:411)\n\tat com.databricks.sql.transaction.tahoe.commands.WriteIntoDeltaEdge.writeAndReturnCommitData(WriteIntoDeltaEdge.scala:256)\n\tat com.databricks.sql.transaction.tahoe.commands.WriteIntoDeltaEdge.$anonfun$run$2(WriteIntoDeltaEdge.scala:182)\n\tat com.databricks.sql.transaction.tahoe.DeltaLog.withNewTransaction(DeltaLog.scala:325)\n\tat com.databricks.sql.transaction.tahoe.commands.WriteIntoDeltaEdge.$anonfun$run$1(WriteIntoDeltaEdge.scala:169)\n\tat com.databricks.sql.acl.CheckPermissions$.$anonfun$trusted$2(CheckPermissions.scala:2642)\n\tat com.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:63)\n\tat com.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:60)\n\tat com.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:235)\n\tat com.databricks.sql.acl.CheckPermissions$.trusted(CheckPermissions.scala:2642)\n\tat com.databricks.sql.transaction.tahoe.commands.WriteIntoDeltaEdge.run(WriteIntoDeltaEdge.scala:168)\n\tat com.databricks.sql.transaction.tahoe.catalog.WriteIntoDeltaBuilder$$anon$3$$anon$4.insert(DeltaTableV2.scala:1071)\n\tat org.apache.spark.sql.execution.datasources.v2.SupportsV1Write.writeWithV1(V1FallbackWriters.scala:136)\n\tat org.apache.spark.sql.execution.datasources.v2.SupportsV1Write.writeWithV1$(V1FallbackWriters.scala:117)\n\tat org.apache.spark.sql.execution.datasources.v2.AppendDataExecV1.writeWithV1(V1FallbackWriters.scala:35)\n\tat org.apache.spark.sql.execution.datasources.v2.V1FallbackWriters.run(V1FallbackWriters.scala:83)\n\tat org.apache.spark.sql.execution.datasources.v2.V1FallbackWriters.run$(V1FallbackWriters.scala:81)\n\tat org.apache.spark.sql.execution.datasources.v2.AppendDataExecV1.run(V1FallbackWriters.scala:35)\n\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.$anonfun$result$2(V2CommandExec.scala:48)\n\tat org.apache.spark.sql.execution.SparkPlan.runCommandInAetherOrSpark(SparkPlan.scala:195)\n\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.$anonfun$result$1(V2CommandExec.scala:48)\n\tat com.databricks.spark.util.FrameProfiler$.$anonfun$record$1(FrameProfiler.scala:114)\n\tat com.databricks.spark.util.FrameProfilerExporter$.maybeExportFrameProfiler(FrameProfilerExporter.scala:200)\n\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:105)\n\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:47)\n\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:45)\n\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:56)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$5(QueryExecution.scala:596)\n\tat com.databricks.util.LexicalThreadLocal$Handle.runWith(LexicalThreadLocal.scala:63)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$4(QueryExecution.scala:596)\n\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:265)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$3(QueryExecution.scala:595)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$18(SQLExecution.scala:600)\n\tat com.databricks.sql.util.MemoryTrackerHelper.withMemoryTracking(MemoryTrackerHelper.scala:111)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$16(SQLExecution.scala:513)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSessionTagsApplied(SQLExecution.scala:932)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$15(SQLExecution.scala:434)\n\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:97)\n\tat org.apache.spark.sql.artifact.ArtifactManager.$anonfun$withResources$1(ArtifactManager.scala:124)\n\tat org.apache.spark.sql.artifact.ArtifactManager.withClassLoaderIfNeeded(ArtifactManager.scala:118)\n\tat org.apache.spark.sql.artifact.ArtifactManager.withResources(ArtifactManager.scala:123)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$14(SQLExecution.scala:434)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:967)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$1(SQLExecution.scala:433)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:860)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId0(SQLExecution.scala:255)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:885)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$2(QueryExecution.scala:591)\n\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:1607)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$1(QueryExecution.scala:587)\n\tat org.apache.spark.sql.execution.QueryExecution.withMVTagsIfNecessary(QueryExecution.scala:528)\n\tat org.apache.spark.sql.execution.QueryExecution.org$apache$spark$sql$execution$QueryExecution$$eagerlyExecute$1(QueryExecution.scala:585)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$8$1.applyOrElse(QueryExecution.scala:702)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$8$1.applyOrElse(QueryExecution.scala:694)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:543)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:121)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:543)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:45)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:361)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:357)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:45)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:45)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:519)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$8(QueryExecution.scala:694)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:418)\n\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:694)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyCommandExecuted$1(QueryExecution.scala:484)\n\tat scala.util.Try$.apply(Try.scala:217)\n\tat org.apache.spark.util.Utils$.doTryWithCallerStacktrace(Utils.scala:1684)\n\tat org.apache.spark.util.Utils$.getTryWithCallerStacktrace(Utils.scala:1745)\n\tat org.apache.spark.util.LazyTry.get(LazyTry.scala:75)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:489)\n\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:730)\n\tat org.apache.spark.sql.classic.DataFrameWriter.runCommand(DataFrameWriter.scala:854)\n\tat org.apache.spark.sql.classic.DataFrameWriter.saveAsTable(DataFrameWriter.scala:702)\n\tat org.apache.spark.sql.classic.DataFrameWriter.saveAsTable(DataFrameWriter.scala:609)\n\tat org.apache.spark.sql.connect.planner.SparkConnectPlanner.handleWriteOperation(SparkConnectPlanner.scala:4092)\n\tat org.apache.spark.sql.connect.planner.SparkConnectPlanner.process(SparkConnectPlanner.scala:3450)\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.handleCommand(ExecuteThreadRunner.scala:385)\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.$anonfun$executeInternal$1(ExecuteThreadRunner.scala:281)\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.$anonfun$executeInternal$1$adapted(ExecuteThreadRunner.scala:238)\n\tat org.apache.spark.sql.connect.service.SessionHolder.$anonfun$withSession$2(SessionHolder.scala:532)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:860)\n\tat org.apache.spark.sql.connect.service.SessionHolder.$anonfun$withSession$1(SessionHolder.scala:532)\n\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:97)\n\tat org.apache.spark.sql.artifact.ArtifactManager.$anonfun$withResources$1(ArtifactManager.scala:124)\n\tat org.apache.spark.sql.artifact.ArtifactManager.withClassLoaderIfNeeded(ArtifactManager.scala:118)\n\tat org.apache.spark.sql.artifact.ArtifactManager.withResources(ArtifactManager.scala:123)\n\tat org.apache.spark.sql.connect.service.SessionHolder.withSession(SessionHolder.scala:531)\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.executeInternal(ExecuteThreadRunner.scala:238)\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.$anonfun$execute$1(ExecuteThreadRunner.scala:141)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n\tat com.databricks.spark.connect.service.UtilizationMetrics.recordActiveQueries(UtilizationMetrics.scala:43)\n\tat com.databricks.spark.connect.service.UtilizationMetrics.recordActiveQueries$(UtilizationMetrics.scala:40)\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.recordActiveQueries(ExecuteThreadRunner.scala:53)\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.org$apache$spark$sql$connect$execution$ExecuteThreadRunner$$execute(ExecuteThreadRunner.scala:139)\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner$ExecutionThread.$anonfun$run$2(ExecuteThreadRunner.scala:586)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n\tat com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)\n\tat com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)\n\tat com.databricks.unity.HandleImpl.$anonfun$runWithAndClose$1(UCSHandle.scala:109)\n\tat scala.util.Using$.resource(Using.scala:296)\n\tat com.databricks.unity.HandleImpl.runWithAndClose(UCSHandle.scala:108)\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner$ExecutionThread.run(ExecuteThreadRunner.scala:586)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    wrong_schema_df = spark.createDataFrame(\n",
    "        [(\"a\", \"b\", \"c\")],\n",
    "        [\"x\", \"y\", \"z\"]\n",
    "    )\n",
    "\n",
    "    wrong_schema_df.write \\\n",
    "        .format(\"delta\") \\\n",
    "        .mode(\"append\") \\\n",
    "        .saveAsTable(\"workspace.ecommerce.events_delta\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Schema enforcement works:\")\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b066d9a3-f95e-4e29-9b7c-952bd731e4c2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----------+----------+-------------------+------------------+--------+------+---------+--------------------+\n|         event_time|event_type|product_id|        category_id|     category_code|   brand| price|  user_id|        user_session|\n+-------------------+----------+----------+-------------------+------------------+--------+------+---------+--------------------+\n|2019-11-29 04:24:47|      view|   5100644|2053013553341792533|electronics.clocks|  garmin|159.58| 96041329|3c3bb8ed-14c0-41f...|\n|2019-11-26 07:38:59|      view|  34800084|2062461754293617058|              NULL|  cantra| 128.7|105201424|c9aadb18-c9c7-425...|\n|2019-11-28 08:25:09|      view|  12702958|2053013553559896355|              NULL|cordiant| 42.47|122384079|6cee7edb-68ae-4be...|\n|2019-11-14 02:36:19|      view|  12720549|2053013553559896355|              NULL|cordiant| 37.32|149382035|360ac34e-7942-450...|\n|2019-11-21 11:07:21|      view|  13100014|2053013553526341921|              NULL|    skad|325.26|171409616|28d951f1-828b-4b8...|\n+-------------------+----------+----------+-------------------+------------------+--------+------+---------+--------------------+\nonly showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import row_number\n",
    "\n",
    "dedup_window = Window.partitionBy(\n",
    "    \"user_id\", \"product_id\", \"event_time\"\n",
    ").orderBy(\"event_time\")\n",
    "\n",
    "dedup_df = (\n",
    "    df.withColumn(\"rn\", row_number().over(dedup_window))\n",
    "      .filter(\"rn = 1\")\n",
    "      .drop(\"rn\")\n",
    ")\n",
    "\n",
    "dedup_df.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ea2dceee-e1f5-47a5-94dd-c19eb22a0ab6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>num_affected_rows</th><th>num_updated_rows</th><th>num_deleted_rows</th><th>num_inserted_rows</th></tr></thead><tbody><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         0,
         0,
         0,
         0
        ]
       ],
       "datasetInfos": [
        {
         "name": "_sqldf",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "num_affected_rows",
            "nullable": true,
            "type": "long"
           },
           {
            "metadata": {},
            "name": "num_updated_rows",
            "nullable": true,
            "type": "long"
           },
           {
            "metadata": {},
            "name": "num_deleted_rows",
            "nullable": true,
            "type": "long"
           },
           {
            "metadata": {},
            "name": "num_inserted_rows",
            "nullable": true,
            "type": "long"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.connect.dataframe.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 13
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "num_affected_rows",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "num_updated_rows",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "num_deleted_rows",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "num_inserted_rows",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "MERGE INTO workspace.ecommerce.events_delta t\n",
    "USING workspace.ecommerce.events_delta s\n",
    "ON t.user_id = s.user_id\n",
    "AND t.product_id = s.product_id\n",
    "AND t.event_time = s.event_time\n",
    "WHEN NOT MATCHED THEN INSERT *\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 8776610881030996,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Untitled Notebook 2026-01-12 22:05:54",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}