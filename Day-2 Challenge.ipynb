{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0e65c35d-4189-417a-84b5-1a59d4855f4a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## Apache Spark's architecture is designed for speed and scalability, utilizing a master-worker model that enables efficient distributed computing for big data processing.\n",
    "# Core Components of Spark Architecture\n",
    "# Driver Program: The driver acts as the master node, running the main application and creating the Spark context. It converts user-defined transformations into a Directed Acyclic Graph (DAG) and splits jobs into stages and tasks, which are then sent to executors for execution. \n",
    "# 2\n",
    "# Executors: These are the worker nodes that execute the tasks assigned by the driver. Each executor runs in its own JVM and is responsible for executing the tasks and returning the results to the driver. Executors also manage memory and cache data for faster access. \n",
    "# 2\n",
    "# Cluster Manager: The cluster manager allocates resources (CPU, memory) across the worker nodes. Spark can work with various cluster managers, including its own standalone manager, Apache Mesos, and Hadoop YARN. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "24c1f0fa-59d7-470d-8e63-c7e4228fac07",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# RDD (Resilient Distributed Dataset)\n",
    "\n",
    "# RDD is the fundamental data structure in Spark, representing an immutable distributed collection of objects. It allows for parallel processing and can be created from various data sources, including Hadoop Distributed File System (HDFS), local file system, and relational databases. RDDs offer two types of operations: transformations and actions. Transformations create a new RDD from an existing one, while actions return a result to the driver program or write data to external storage.\n",
    "\n",
    "# DataFrame\n",
    "\n",
    "# DataFrame is a higher-level abstraction introduced in Spark 1.3 to overcome the limitations of RDDs. It represents a distributed collection of data organized into named columns, similar to a table in a relational database or a spreadsheet. DataFrames support a wide range of operations and transformations, such as filtering, aggregating, joining, and grouping data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "854d5b94-689f-4a29-9fad-4a1159a838f7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# `%fs`: Access Databricks File System (DBFS)\n",
    "# `%sql`: Run SQL Queries\n",
    "# `%sh`: Execute Shell Commands\n",
    "# `%md`: Add Markdown\n",
    "# `%run`: Run External Notebooks\n",
    "# `%python`, `%r`, `%scala`: Switch Between Languages\n",
    "# `%pip`: Manage Python Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "78e7995b-559e-466c-82b8-149dd8e5bd5a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----------+----------+-------------------+--------------------+------+------+---------+--------------------+\n|         event_time|event_type|product_id|        category_id|       category_code| brand| price|  user_id|        user_session|\n+-------------------+----------+----------+-------------------+--------------------+------+------+---------+--------------------+\n|2019-11-01 00:00:00|      view|   1003461|2053013555631882655|electronics.smart...|xiaomi|489.07|520088904|4d3b30da-a5e4-49d...|\n|2019-11-01 00:00:00|      view|   5000088|2053013566100866035|appliances.sewing...|janome|293.65|530496790|8e5f4f83-366c-4f7...|\n|2019-11-01 00:00:01|      view|  17302664|2053013553853497655|                NULL| creed| 28.31|561587266|755422e7-9040-477...|\n|2019-11-01 00:00:01|      view|   3601530|2053013563810775923|appliances.kitche...|    lg|712.87|518085591|3bfb58cd-7892-48c...|\n|2019-11-01 00:00:01|      view|   1004775|2053013555631882655|electronics.smart...|xiaomi|183.27|558856683|313628f1-68b8-460...|\n+-------------------+----------+----------+-------------------+--------------------+------+------+---------+--------------------+\nonly showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(\n",
    "    \"/Volumes/workspace/ecommerce/ecommerce_data\",\n",
    "    header=True,\n",
    "    inferSchema=True\n",
    ")\n",
    "\n",
    "df.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "545906bd-206a-4153-ad17-b0d2cb2fa60b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+------+\n|event_type|   brand| price|\n+----------+--------+------+\n|      view|  xiaomi|489.07|\n|      view|  janome|293.65|\n|      view|   creed| 28.31|\n|      view|      lg|712.87|\n|      view|  xiaomi|183.27|\n|      view|      hp|360.09|\n|      view|      hp|514.56|\n|      view| rondell| 30.86|\n|      view|michelin| 72.72|\n|      view|   apple|732.07|\n+----------+--------+------+\nonly showing top 10 rows\n+----------+---------+\n|event_type|    count|\n+----------+---------+\n|  purchase|  1659788|\n|      cart|  3955446|\n|      view|104335509|\n+----------+---------+\n\n+-------+--------+\n|  brand|   count|\n+-------+--------+\n|   NULL|15331243|\n|samsung|13172020|\n|  apple|10381933|\n| xiaomi| 7721825|\n| huawei| 2521331|\n+-------+--------+\n\n"
     ]
    }
   ],
   "source": [
    "df.select(\"event_type\", \"brand\", \"price\").show(10)\n",
    "\n",
    "df.filter(df.price > 100).count()\n",
    "\n",
    "df.groupBy(\"event_type\").count().show()\n",
    "\n",
    "df.groupBy(\"brand\") \\\n",
    "  .count() \\\n",
    "  .orderBy(\"count\", ascending=False) \\\n",
    "  .limit(5) \\\n",
    "  .show()\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Untitled Notebook 2026-01-10 16:41:15",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}