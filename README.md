## IDC AI Challenge â€” Databricks Learning Journey

This repository documents my 21-day AI challenge conducted by [Indian Data Club (IDC)](https://www.linkedin.com/company/indian-data-club/posts/?feedView=all) and [Codebasics](https://www.linkedin.com/company/codebasics/), focused on building end-to-end data engineering and AI solutions using Databricks.
The journey progresses from core Spark & Delta Lake concepts to analytics, ML, and a real-world capstone project.

## ðŸ“Œ Learning Phases Overview
- PHASE 1: Foundation (Days 1â€“4)

  - Databricks & Lakehouse fundamentals

  - Apache Spark architecture & PySpark basics

  - Data transformations, joins, window functions

  - Delta Lake concepts & ACID transactions

- PHASE 2: Data Engineering (Days 5â€“8)

  - Advanced Delta Lake (Time Travel, MERGE, OPTIMIZE)
  - Medallion Architecture (Bronze â†’ Silver â†’ Gold)
  - Databricks workflows & job orchestration
  - Unity Catalog & data governance

- PHASE 3: Advanced Analytics (Days 9â€“11)

  - SQL Warehouses & dashboards
  - Performance optimization techniques
  - Statistical analysis & ML-ready feature engineering

- PHASE 4: AI & Machine Learning (Days 12â€“14)

  - MLflow experiment tracking & model registry
  - Model comparison & Spark ML pipelines
  - AI-powered analytics using Databricks Genie & Mosaic AI

## ðŸš€ Capstone Project (Days 15â€“21)

A self-driven, real-world project applying everything learned:

- Data ingestion & transformation

- Delta Lake & medallion architecture

- Analytics, ML models, and AI insights

## ðŸŽ¯ Goal

Build practical, scalable, and portfolio-ready AI solutions while gaining hands-on experience with Databricks, Data Engineering, and Machine Learning.
